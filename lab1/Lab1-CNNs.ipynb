{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d97f7c5d-46f3-4cbd-80ad-f1e50cd65096",
   "metadata": {},
   "source": [
    "# Deep Learning Applications: Laboratory #1\n",
    "\n",
    "In this first laboratory we will work relatively simple architectures to get a feel for working with Deep Models. This notebook is designed to work with PyTorch, but as I said in the introductory lecture: please feel free to use and experiment with whatever tools you like.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17ed8906-bd19-4b4f-8b79-4feae355ffd6",
   "metadata": {},
   "source": [
    "## Exercise 1: Warming Up\n",
    "In this series of exercises I want you to try to duplicate (on a small scale) the results of the ResNet paper:\n",
    "\n",
    "> [Deep Residual Learning for Image Recognition](https://arxiv.org/abs/1512.03385), Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun, CVPR 2016.\n",
    "\n",
    "We will do this in steps using a Multilayer Perceptron on MNIST.\n",
    "\n",
    "Recall that the main message of the ResNet paper is that **deeper** networks do not **guarantee** more reduction in training loss (or in validation accuracy). Below you will incrementally build a sequence of experiments to verify this for an MLP. A few guidelines:\n",
    "\n",
    "+ I have provided some **starter** code at the beginning. **NONE** of this code should survive in your solutions. Not only is it **very** badly written, it is also written in my functional style that also obfuscates what it's doing (in part to **discourage** your reuse!). It's just to get you *started*.\n",
    "+ These exercises ask you to compare **multiple** training runs, so it is **really** important that you factor this into your **pipeline**. Using [Tensorboard](https://pytorch.org/tutorials/recipes/recipes/tensorboard_with_pytorch.html) is a **very** good idea -- or, even better [Weights and Biases](https://wandb.ai/site).\n",
    "+ You may work and submit your solutions in **groups of at most two**. Share your ideas with everyone, but the solutions you submit *must be your own*.\n",
    "\n",
    "First some boilerplate to get you started, then on to the actual exercises!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab3a8282-2322-4dca-b76e-2f3863bc75fb",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "start_time": "2023-05-01T14:08:03.101621Z",
     "end_time": "2023-05-01T14:08:03.283409Z"
    }
   },
   "outputs": [],
   "source": [
    "from os import chdir\n",
    "from pathlib import Path\n",
    "import random\n",
    "\n",
    "# Start with some standard imports.\n",
    "import numpy as np\n",
    "import torchmetrics\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from functools import reduce\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import Subset,SubsetRandomSampler,Dataset\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import wandb\n",
    "\n",
    "from data_loader import SubsetDataset\n",
    "from trainer import Trainer\n",
    "\n",
    "# some utility functions\n",
    "# sets current directory a the notebook's parent\n",
    "def make_paths_relative_to_root():\n",
    "    \"\"\"Always use the same, absolute (relative to root) paths\n",
    "    which makes moving the notebooks around easier.\n",
    "    \"\"\"\n",
    "    top_level = Path(__file__).parent\n",
    "    chdir(top_level)\n",
    "\n",
    "# functions to show an image\n",
    "def imshow(img, one_channel=False):\n",
    "    if one_channel:\n",
    "        img = img.mean(dim=0)\n",
    "    img = img / 2 + 0.5  # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    if one_channel:\n",
    "        plt.imshow(npimg, cmap=\"Greys\")\n",
    "    else:\n",
    "        plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "\n",
    "#Global setting\n",
    "BATCH_SIZE = 128\n",
    "DEVICE = 'cuda:0'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33cc12cc-8422-47bf-8d8e-0950ac05ae96",
   "metadata": {},
   "source": [
    "#### Data preparation\n",
    "I define a custom class `SubsetDataset`, which wraps a `Subset` into a `Dataset` object. This will be useful when we'll want to use a different transformation from training and validation set on CIFAR-10.\n",
    "10% of training data is used for validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "272a69db-0416-444a-9be4-5f055ff48bbb",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "start_time": "2023-05-01T14:08:03.132831Z",
     "end_time": "2023-05-01T14:08:03.322756Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load CIFAR train\n",
    "dataset = datasets.MNIST(root='/data',train=True,download=True)\n",
    "\n",
    "# # # Data augmentation and normalization for training\n",
    "# # # Just normalization for validation\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "\n",
    "# Split train into train and validation.\\n,\n",
    "val_size = int(0.1*len(dataset))\n",
    "I = np.random.permutation(len(dataset))\n",
    "ds_val = SubsetDataset(Subset(dataset, I[:val_size]),transform)\n",
    "ds_train = SubsetDataset(Subset(dataset, I[val_size:]),transform)\n",
    "\n",
    "train_data_loader = DataLoader(ds_train,batch_size=BATCH_SIZE,shuffle=True)\n",
    "valid_data_loader = DataLoader(ds_val,batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24e05e96-7707-4490-98b8-50cb5e330af1",
   "metadata": {},
   "source": [
    "#### Training and evaluation code\n",
    "\n",
    "I will use WandB to log all the experiments.\n",
    "MLP experiments are available [here](https://wandb.ai/dla-darcio/lab-1-mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: Currently logged in as: \u001B[33mdario-cioni\u001B[0m (\u001B[33mdla-darcio\u001B[0m). Use \u001B[1m`wandb login --relogin`\u001B[0m to force relogin\n"
     ]
    }
   ],
   "source": [
    "wandb.login()\n",
    "\n",
    "wandb_config = {\n",
    "    \"project\":\"lab-1-mlp\"\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-01T14:08:03.291468Z",
     "end_time": "2023-05-01T14:08:08.949536Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The `Trainer` will contain all the training logic, for simplicity we fixed the following parameters:\n",
    "- Loss will be always categorical cross-entropy and will be logged during training and validation\n",
    "- Top-1 accuracy will be logged during model training and validation\n",
    "- Model's gradients will be also logged during training by WandB utility `wandb.watch`."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "id": "875008c3-306c-4e39-a845-d7bda7862621",
   "metadata": {},
   "source": [
    "### MLP definition\n",
    "Here I define a MLP class, which allows to specify the dimension of each layer by passing an array\n",
    "```python\n",
    "model_mlp = MLP([768,16,16,10])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8c1e503a-37df-4fb9-94e7-85d0adb494bd",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "start_time": "2023-05-01T14:08:08.965103Z",
     "end_time": "2023-05-01T14:08:09.136980Z"
    }
   },
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, layer_sizes):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        for (in_dim,out_dim) in zip(layer_sizes[:-1], layer_sizes[1:]):\n",
    "            layers.append(nn.Linear(in_dim,out_dim))\n",
    "            layers.append(nn.ReLU())\n",
    "        self.layers = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = x.view(x.shape[0],-1)\n",
    "        out = self.layers(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ae06e26-8fa3-414e-a502-8d1c18ba9eb7",
   "metadata": {},
   "source": [
    "### Training configuration\n",
    "\n",
    "To allow faster experimentation, all the configuration is defined through dictionaries and then logged into WandB.\n",
    "\n",
    "For the MNIST MLP\n",
    "- I trained the network for 30 epochs with a learning rate of $10^{-4}$ using Adam optimizer.\n",
    "- Batch size is 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fc89e48f-d8f3-4122-842d-1ff389499854",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "start_time": "2023-05-01T14:08:09.011988Z",
     "end_time": "2023-05-01T14:08:13.325924Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01718333333337796, max=1.0)…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "245908b496af45c9b0a3d81699e06842"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "wandb version 0.15.0 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Tracking run with wandb version 0.14.2"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Run data is saved locally in <code>C:\\Users\\Dario\\DataspellProjects\\DLA\\lab1\\wandb\\run-20230501_140809-q5gzbkfn</code>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Syncing run <strong><a href='https://wandb.ai/dla-darcio/lab-1-mlp/runs/q5gzbkfn' target=\"_blank\">lunar-night-4</a></strong> to <a href='https://wandb.ai/dla-darcio/lab-1-mlp' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View project at <a href='https://wandb.ai/dla-darcio/lab-1-mlp' target=\"_blank\">https://wandb.ai/dla-darcio/lab-1-mlp</a>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View run at <a href='https://wandb.ai/dla-darcio/lab-1-mlp/runs/q5gzbkfn' target=\"_blank\">https://wandb.ai/dla-darcio/lab-1-mlp/runs/q5gzbkfn</a>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "input_size = 28*28\n",
    "\n",
    "# Training hyperparameters.\n",
    "trainer_hparams={\n",
    "    \"epochs\":30,\n",
    "    \"lr\":0.0001,\n",
    "    \"batch_size\":128\n",
    "}\n",
    "\n",
    "# Architecture hyperparameters.\n",
    "arch_hparams={\n",
    "    \"width\":100,\n",
    "    \"depth\":2\n",
    "}\n",
    "\n",
    "config = {\n",
    "    **trainer_hparams,\n",
    "    **arch_hparams\n",
    "}\n",
    "\n",
    "writer = wandb.init(**wandb_config,config=config)\n",
    "# Define a DataLoader for MNIST with train and validation split\n",
    "\n",
    "# Instantiate model and optimizer.\n",
    "config = writer.config\n",
    "model_mlp = MLP([input_size] + [config.width]*config.depth + [10]).to(DEVICE)\n",
    "opt = torch.optim.Adam(params=model_mlp.parameters(), lr=config.lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de2cad13-ee2c-4e43-b5c7-31760da8c2df",
   "metadata": {},
   "source": [
    "### Exercise 1.1: A baseline MLP\n",
    "\n",
    "Implement a *simple* Multilayer Perceptron to classify the 10 digits of MNIST (e.g. two *narrow* layers). Use my code above as inspiration, but implement your own training pipeline -- you will need it later. Train this model to convergence, monitoring (at least) the loss and accuracy on the training and validation sets for every epoch. Below I include a basic implementation to get you started -- remember that you should write your *own* pipeline!\n",
    "\n",
    "**Note**: This would be a good time to think about *abstracting* your model definition, and training and evaluation pipelines in order to make it easier to compare performance of different models.\n",
    "\n",
    "**Important**: Given the *many* runs you will need to do, and the need to *compare* performance between them, this would **also** be a great point to study how **Tensorboard** or **Weights and Biases** can be used for performance monitoring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Begin training\n",
    "trainer = Trainer(opt,writer,epochs=config.epochs,device=DEVICE)\n",
    "trainer.train(model_mlp,train_data_loader,valid_data_loader)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "id": "0fb8ad9b-e3ae-4c49-9bec-35aaea149b08",
   "metadata": {},
   "source": [
    "### Exercise 1.2: Rinse and Repeat\n",
    "\n",
    "Repeat the verification you did above, but with **Convolutional** Neural Networks. If you were careful about abstracting your model and training code, this should be a simple exercise. Show that **deeper** CNNs *without* residual connections do not always work better and **even deeper** ones *with* residual connections.\n",
    "\n",
    "**Hint**: You probably should do this exercise using CIFAR10, since MNIST is *very* easy (at least up to about 99% accuracy).\n",
    "\n",
    "**Spoiler**: If you plan to do optional exercise 3.3, you should think *very* carefully about the architectures of your CNNs here (so you can reuse them!).\n",
    "\n",
    "#### Data preparation\n",
    "Here I define my dataset for CIFAR-10. Input images are per-pixel normalized along every channel\n",
    "\n",
    "I performed data augmentation as in the paper\n",
    "- The 32x32 is padded with 4 pixel on each side\n",
    "- A random crop of 32x32 is taken from the padded image or its horizontal flip\n",
    "\n",
    "Validation is 10% of training dataset. On this set, I only perform per-pixel normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Load CIFAR train\n",
    "dataset = datasets.CIFAR10(root='/data',train=True,download=True)\n",
    "\n",
    "# # # Data augmentation and normalization for training\n",
    "# # # Just normalization for validation\n",
    "transform = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomCrop(32,4),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.49139968,0.48215841,0.44653091),(0.24703223,0.24348513,0.26158784))\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.49139968,0.48215841,0.44653091),(0.24703223,0.24348513,0.26158784))\n",
    "    ]),\n",
    "}\n",
    "\n",
    "# Split train into train and validation.\n",
    "val_size = int(0.1*len(dataset))\n",
    "I = np.random.permutation(len(dataset))\n",
    "ds_train = SubsetDataset(Subset(dataset, I[val_size:]),transform['train'])\n",
    "ds_val = SubsetDataset(Subset(dataset, I[:val_size]),transform['val'])\n",
    "\n",
    "\n",
    "train_data_loader = DataLoader(ds_train,batch_size=BATCH_SIZE,shuffle=True)\n",
    "valid_data_loader = DataLoader(ds_val,batch_size=BATCH_SIZE)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-01T14:08:14.595833Z",
     "end_time": "2023-05-01T14:08:16.125960Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "To make sure that the the images and labels are in the correct shape let's display a few samples. We can see that the images are not centered anymore, because of the data augmentation procedure we used"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 3, 32, 32]) torch.Size([128])\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataiter = iter(train_data_loader)\n",
    "images,labels = next(dataiter)\n",
    "print(images.shape, labels.shape)\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images[0:4]))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-01T14:08:16.393994Z",
     "end_time": "2023-05-01T14:08:16.899143Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Here I define the convolutional network, which follows the ResNet definition of the paper for CIFAR-10.\n",
    "The network is composed by an initial $3\\times3$ convolutional layer, followed by a stack of $6n$ layers with $3 \\times 3$ convolutions on feature maps of sizes {32,16,8}, with $2n$ layers for each feature map size.\n",
    "The number of filters is doubled every time the size of the feature map is halved, to mantain the same number of operations.\n",
    "\n",
    "\n",
    "| Output map size | 32 x 32 | 16 x 16 | 8 x 8 |\n",
    "|-----------------|---------|---------|-------|\n",
    "| # layers        | 1 + 2n  | 2n      | 2n    |\n",
    "| # filters       | 16      | 32      | 64    |\n",
    "\n",
    "#### Residual Block\n",
    "To allow an easy modification of the model's depth and enabling/disabling residual connections, I created a `ResidualBlock` Module, which allows to add blocks of two convolutional layers to the network.\n",
    "- The block consists of two convolutional layers, each followed by a Batch Normalization Layer before the ReLU activation.\n",
    "- Downsampling is obtained with a strided convolution performed by the first convolutional layer.\n",
    "- The residual connection is obtained by summing the input feature maps before the second nonlinearity. Since summmation is allowed only if the feature maps have the same shape, a projection layer is added to the residual connection when downsampling is performed.\n",
    "\n",
    "#### Projection\n",
    "The paper experiments with three types of projection. I provide an implementation of all three\n",
    "    A) Parameter-free projection, performed by downsampling the input feature map and padding the remaining channels with zeros\n",
    "    B) Paremeterized projection with an affine trasformation, followed by a Batch Normalization layer.\n",
    "    C) Add a parameterized projection to all residual connections\n",
    "\n",
    "#### Global Average Pooling\n",
    "The ResNet use a Global Average Pooling layer followed by a Fully connected layer, as defined in [[2](https://arxiv.org/pdf/1312.4400.pdf)]. The Global Average Pooling transforms a feature map $H \\times W \\times C$ into $1 \\times 1 \\times C$.\n",
    "If $C = $ num_classes, the resulting tensor could be directly fed into a softmax for prediction, however we employ a single Fully Connected layer, as done in the paper.\n",
    "\n",
    "#### Initialization\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3c8baa0e-b17f-4a77-8a88-dadfdc6763ea",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-05-01T14:08:22.209370Z",
     "end_time": "2023-05-01T14:08:22.265327Z"
    }
   },
   "outputs": [],
   "source": [
    "class DownsampleA(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride):\n",
    "        super().__init__()\n",
    "        self.downsample = nn.AvgPool2d(kernel_size=1,stride=stride)\n",
    "\n",
    "    def forward(self,x):\n",
    "        d = self.downsample(x)\n",
    "        # Here I assume stride is only 2.\n",
    "        out = torch.concat([d, torch.zeros_like(d)],dim=1)\n",
    "        return out\n",
    "\n",
    "class DownsampleB(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride):\n",
    "        super().__init__()\n",
    "        self.downsample = nn.Sequential(\n",
    "            nn.Conv2d(in_channels,out_channels,kernel_size=1,stride=stride,bias=False),\n",
    "            nn.BatchNorm2d(out_channels)\n",
    "        )\n",
    "\n",
    "    def forward(self,x):\n",
    "        out = self.downsample(x)\n",
    "        return out\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, residual=True, residual_type='b', stride=1):\n",
    "        super().__init__()\n",
    "        self.residual = residual\n",
    "        self.residual_type = residual_type.lower()\n",
    "        self.stride = stride\n",
    "        if residual:\n",
    "            if self.residual_type == 'a' and (in_channels != out_channels or stride>1):\n",
    "                self.project = DownsampleA(in_channels,out_channels,stride)\n",
    "            if self.residual_type == 'b' and (in_channels != out_channels or stride>1):\n",
    "                self.project = DownsampleB(in_channels,out_channels,stride)\n",
    "            if self.residual_type == 'c':\n",
    "                self.project = DownsampleB(in_channels,out_channels,stride)\n",
    "        # vgg has strided conv instead of maxpool\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1,stride=stride,bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1,bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # first conv\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = F.relu(out)\n",
    "        # second conv\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        # residual connection\n",
    "        if self.residual:\n",
    "            res = x if x.shape == out.shape else self.project(x)\n",
    "            out+= res\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "class TinyResNet(nn.Module):\n",
    "    def __init__(self, layers, num_classes=10,residual=False,residual_type='b',num_channels=16):\n",
    "        super().__init__()\n",
    "        self.residual = residual\n",
    "        self.residual_type = residual_type\n",
    "        self.conv1 = nn.Conv2d(3,num_channels,3,padding=1,bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(num_channels)\n",
    "        # stack 3 convolutional block of 2n layers each, with first block performing a downsampling (only in 2nd and 3rd layer for CIFAR)\n",
    "        self.layer1 = self._add_block(in_channels=num_channels,out_channels=num_channels,n_blocks=layers[0],stride=1)\n",
    "        num_channels*=2\n",
    "        self.layer2 = self._add_block(num_channels//2,num_channels,layers[1],stride=2)\n",
    "        num_channels*=2\n",
    "        self.layer3 = self._add_block(num_channels//2,num_channels,layers[2],stride=2)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(num_channels, num_classes)\n",
    "\n",
    "    def _add_block(self,in_channels,out_channels,n_blocks,stride=1):\n",
    "        layers = []\n",
    "        layers.append(ResidualBlock(in_channels,out_channels,self.residual,self.residual_type,stride=stride))\n",
    "        in_channels = out_channels\n",
    "        for i in range(1,n_blocks):\n",
    "            layers.append(ResidualBlock(in_channels,out_channels,self.residual,self.residual_type))\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self,x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = F.relu(out,inplace=True)\n",
    "        # print(out.shape) # 128,16,16,16\n",
    "        out = self.layer1(out)\n",
    "        # print(out.shape) # 128,32,8,8\n",
    "        out = self.layer2(out)\n",
    "        # print(out.shape)\n",
    "        out = self.layer3(out)\n",
    "        # print(out.shape)\n",
    "        # print(out.shape)\n",
    "        out = self.avgpool(out)\n",
    "        out = torch.flatten(out,1)\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Training\n",
    "We can now train convolutional models with and without residual connections.\n",
    "- Used SGD optimizer, since it usually allows better results [[1](https://arxiv.org/pdf/1705.08292.pdf)], but needs to be trained for more epochs than Adam.\n",
    "- Following the paper, I used a momentum of 0.9 and a weight decay of $10^{-4}$.\n",
    "- The learning rate is initially set as 0.1 and divided by 10 at epochs 50 and 75, and training ends at epoch 85.\n",
    "\n",
    "We train four models, with 3 and 9 blocks per layer, leading to 20 and 56 layer architectures, with and without residual connections.\n",
    "Training logs are available [here](https://wandb.ai/dla-darcio/lab-1-resnets) or by executing the following cell"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# %wandb dla-darcio/lab-1-resnets"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: \u001B[33mWARNING\u001B[0m Calling wandb.login() after wandb.init() has no effect.\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Finishing last run (ID:q5gzbkfn) before initializing another..."
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View run <strong style=\"color:#cdcd00\">lunar-night-4</strong> at: <a href='https://wandb.ai/dla-darcio/lab-1-mlp/runs/q5gzbkfn' target=\"_blank\">https://wandb.ai/dla-darcio/lab-1-mlp/runs/q5gzbkfn</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Find logs at: <code>.\\wandb\\run-20230501_140809-q5gzbkfn\\logs</code>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Successfully finished last run (ID:q5gzbkfn). Initializing new run:<br/>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016933333333266395, max=1.0…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e33853ae695846daafbd946cea793e9a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "wandb version 0.15.0 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Tracking run with wandb version 0.14.2"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Run data is saved locally in <code>C:\\Users\\Dario\\DataspellProjects\\DLA\\lab1\\wandb\\run-20230501_140846-ytsvj2lv</code>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Syncing run <strong><a href='https://wandb.ai/dla-darcio/lab-1-resnets/runs/ytsvj2lv' target=\"_blank\">revived-sunset-10</a></strong> to <a href='https://wandb.ai/dla-darcio/lab-1-resnets' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View project at <a href='https://wandb.ai/dla-darcio/lab-1-resnets' target=\"_blank\">https://wandb.ai/dla-darcio/lab-1-resnets</a>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View run at <a href='https://wandb.ai/dla-darcio/lab-1-resnets/runs/ytsvj2lv' target=\"_blank\">https://wandb.ai/dla-darcio/lab-1-resnets/runs/ytsvj2lv</a>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TinyResNet(\n",
      "  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (layer1): Sequential(\n",
      "    (0): ResidualBlock(\n",
      "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): ResidualBlock(\n",
      "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (2): ResidualBlock(\n",
      "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (3): ResidualBlock(\n",
      "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (4): ResidualBlock(\n",
      "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (5): ResidualBlock(\n",
      "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (6): ResidualBlock(\n",
      "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (7): ResidualBlock(\n",
      "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (8): ResidualBlock(\n",
      "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (9): ResidualBlock(\n",
      "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (10): ResidualBlock(\n",
      "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (11): ResidualBlock(\n",
      "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (12): ResidualBlock(\n",
      "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (13): ResidualBlock(\n",
      "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (14): ResidualBlock(\n",
      "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (15): ResidualBlock(\n",
      "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (16): ResidualBlock(\n",
      "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (17): ResidualBlock(\n",
      "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): ResidualBlock(\n",
      "      (project): DownsampleA(\n",
      "        (downsample): AvgPool2d(kernel_size=1, stride=2, padding=0)\n",
      "      )\n",
      "      (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): ResidualBlock(\n",
      "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (2): ResidualBlock(\n",
      "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (3): ResidualBlock(\n",
      "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (4): ResidualBlock(\n",
      "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (5): ResidualBlock(\n",
      "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (6): ResidualBlock(\n",
      "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (7): ResidualBlock(\n",
      "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (8): ResidualBlock(\n",
      "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (9): ResidualBlock(\n",
      "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (10): ResidualBlock(\n",
      "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (11): ResidualBlock(\n",
      "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (12): ResidualBlock(\n",
      "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (13): ResidualBlock(\n",
      "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (14): ResidualBlock(\n",
      "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (15): ResidualBlock(\n",
      "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (16): ResidualBlock(\n",
      "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (17): ResidualBlock(\n",
      "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): ResidualBlock(\n",
      "      (project): DownsampleA(\n",
      "        (downsample): AvgPool2d(kernel_size=1, stride=2, padding=0)\n",
      "      )\n",
      "      (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): ResidualBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (2): ResidualBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (3): ResidualBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (4): ResidualBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (5): ResidualBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (6): ResidualBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (7): ResidualBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (8): ResidualBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (9): ResidualBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (10): ResidualBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (11): ResidualBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (12): ResidualBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (13): ResidualBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (14): ResidualBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (15): ResidualBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (16): ResidualBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (17): ResidualBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=64, out_features=10, bias=True)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 85:  32%|███▏      | 113/352 [00:27<01:00,  3.97it/s, step_accuracy=0.992, step_loss=0.0109]"
     ]
    }
   ],
   "source": [
    "wandb.login()\n",
    "\n",
    "wandb_config = {\n",
    "    \"project\":\"lab-1-resnets\"\n",
    "}\n",
    "\n",
    "# Training hyperparameters.\n",
    "trainer_hparams={\n",
    "    \"optimizer\": \"SGD\",\n",
    "    \"epochs\":85,\n",
    "    \"lr\":0.1,\n",
    "    \"wd\": 1e-4,\n",
    "    \"momentum\": 0.9\n",
    "}\n",
    "\n",
    "# Architecture hyperparameters.\n",
    "arch_hparams={\n",
    "    \"layers\":[18]*3,\n",
    "    \"residual\": True,\n",
    "    \"num_classes\":10,\n",
    "    \"num_channels\": 16,\n",
    "    \"residual_type\": 'a'\n",
    "}\n",
    "\n",
    "config = {\n",
    "    **trainer_hparams,\n",
    "    **arch_hparams\n",
    "}\n",
    "\n",
    "# Initialize WandB logging all hyperparameters\n",
    "writer = wandb.init(**wandb_config,config=config)\n",
    "config = wandb.config\n",
    "\n",
    "# Initialize model\n",
    "model = TinyResNet(**arch_hparams).to(DEVICE)\n",
    "print(model)\n",
    "\n",
    "# Get optimizer from torch.optim\n",
    "opt = getattr(torch.optim,config.optimizer)(params=model.parameters(), lr=config.lr, weight_decay=config.wd, momentum=config.momentum)\n",
    "\n",
    "# Get learning rate scheduler\n",
    "lr_scheduler = torch.optim.lr_scheduler.MultiStepLR(opt,milestones=[50,75])\n",
    "\n",
    "# Begin training\n",
    "trainer = Trainer(opt,writer,epochs=config.epochs,device=DEVICE,lr_scheduler=lr_scheduler)\n",
    "trainer.train(model,train_data_loader,valid_data_loader)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-01T14:08:46.729425Z",
     "end_time": "2023-05-01T16:18:35.451536Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Experimental results\n",
    "\n",
    "We can see that the 56-layer network without residual connections obtains a lower validation accuracy than the 20-layer plain net (-4.5%).\n",
    "Both the 20-layer and the 56-layer residual network obtain a higher validation accuracy compared to the plain networks, with the 56-layer residual network leading to the best accuracy, with a slight increase with respect to the 20-layer residual network (+0.3%)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<img src=\"./assets/Plain_Res_accuracy.png\"  width=\"1600\" height=\"800\">"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### We need to go deeper\n",
    "As stated by the [meme](https://knowyourmeme.com/memes/we-need-to-go-deeper), we tried additional, deeper configuration, such as a 101-layer configuration"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "id": "ef4de2f2-abc5-4f98-9eaf-3497f734a022",
   "metadata": {},
   "source": [
    "-----\n",
    "## Exercise 2: Choose at Least One\n",
    "\n",
    "Below are **three** exercises that ask you to deepen your understanding of Deep Networks for visual recognition. You must choose **at least one** of the below for your final submission -- feel free to do **more**, but at least **ONE** you must submit."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07978e8e-9f2e-4949-9699-495af6cb6349",
   "metadata": {},
   "source": [
    "### Exercise 2.1: Explain why Residual Connections are so effective\n",
    "Use your two models (with and without residual connections) you developed above to study and **quantify** why the residual versions of the networks learn more effectively.\n",
    "\n",
    "**Hint**: A good starting point might be looking at the gradient magnitudes passing through the networks during backpropagation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "469e81a3-08ca-4549-a2f8-f47cf5a0308b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "440a3a7b-2ed6-4f58-a1b7-5ab1fc432893",
   "metadata": {},
   "source": [
    "### Exercise 2.2: Fully-convolutionalize a network.\n",
    "Take one of your trained classifiers and **fully-convolutionalize** it. That is, turn it into a network that can predict classification outputs at *all* pixels in an input image. Can you turn this into a **detector** of handwritten digits? Give it a try.\n",
    "\n",
    "**Hint 1**: Sometimes the process of fully-convolutionalization is called \"network surgery\".\n",
    "\n",
    "**Hint 2**: To test your fully-convolutionalized networks you might want to write some functions to take random MNIST samples and embed them into a larger image (i.e. in a regular grid or at random positions)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e33c912-0716-44ef-a91b-47ca19a2b2cd",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "start_time": "2023-04-19T11:01:44.862269Z",
     "end_time": "2023-04-19T11:01:44.972206Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load CIFAR train\n",
    "dataset = datasets.MNIST(root='/data',train=True,download=True)\n",
    "\n",
    "# # # Data augmentation and normalization for training\n",
    "# # # Just normalization for validation\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "    # transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "\n",
    "# Split train into train and validation.\\n,\n",
    "val_size = int(0.1*len(dataset))\n",
    "I = np.random.permutation(len(dataset))\n",
    "ds_val = SubsetDataset(Subset(dataset, I[:val_size]),transform)\n",
    "ds_train = SubsetDataset(Subset(dataset, I[val_size:]),transform)\n",
    "\n",
    "train_data_loader = DataLoader(ds_train,batch_size=BATCH_SIZE,shuffle=True)\n",
    "valid_data_loader = DataLoader(ds_val,batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "import cv2\n",
    "from random import randrange\n",
    "new_size = 128\n",
    "dataiter = iter(train_data_loader)\n",
    "img,label = next(dataiter)\n",
    "img = img[0].squeeze()\n",
    "label = label[0]\n",
    "\n",
    "# print(img.shape,label.shape)\n",
    "\n",
    "new_img = np.zeros((new_size, new_size))\n",
    "\n",
    "# randomly select a bottom left corner to use for img\n",
    "x_min, y_min = randrange(new_size - img.shape[0]), randrange(new_size - img.shape[0])\n",
    "x_max, y_max = x_min + img.shape[0], y_min + img.shape[0]\n",
    "\n",
    "x_center = x_min + (x_max-x_min)/2\n",
    "y_center = y_min + (y_max-y_min)/2\n",
    "\n",
    "\n",
    "new_img[x_min:x_max, y_min:y_max] = img\n",
    "# new_img = cv2.rectangle(new_img, (y_max, x_min), (y_min, x_max), 255, 1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-19T11:02:20.988674Z",
     "end_time": "2023-04-19T11:02:21.051698Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(new_img, cmap=\"gray\")\n",
    "\n",
    "plt.plot(y_center, x_center, \"og\", markersize=5)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-19T11:11:06.833387Z",
     "end_time": "2023-04-19T11:11:07.119445Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "id": "8243f811-8227-4c6f-b07f-56e8cd91643a",
   "metadata": {},
   "source": [
    "### Exercise 2.3: *Explain* the predictions of a CNN\n",
    "\n",
    "Use the CNN model you trained in Exercise 1.2 and implement [*Class Activation Maps*](http://cnnlocalization.csail.mit.edu/#:~:text=A%20class%20activation%20map%20for,decision%20made%20by%20the%20CNN.):\n",
    "\n",
    "> B. Zhou, A. Khosla, A. Lapedriza, A. Oliva, and A. Torralba. Learning Deep Features for Discriminative Localization. CVPR'16 (arXiv:1512.04150, 2015).\n",
    "\n",
    "Use your implementation to demonstrate how your trained CNN *attends* to specific image features to recognize *specific* classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d634a700-56c2-48fd-96e0-4c94d1bd0cfe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Your code here."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## References\n",
    "- [1] Ashia C. Wilson, Rebecca Roelofs, Mitchell Stern, Nathan Srebro, and Benjamin Recht. The Marginal Value of Adaptive Gradient Methods in Machine Learning, 2018.\n",
    "- [2] Lin, Min, Qiang Chen, and Shuicheng Yan. \"Network in network.\" arXiv preprint arXiv:1312.4400 (2013)."
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
